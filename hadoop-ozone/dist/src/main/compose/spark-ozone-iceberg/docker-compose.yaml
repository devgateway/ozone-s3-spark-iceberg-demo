# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

version: "3.8"

# reusable fragments (see https://docs.docker.com/compose/compose-file/#extension-fields)
x-common-config:
  &common-config
  image: ${OZONE_RUNNER_IMAGE}:${OZONE_RUNNER_VERSION}
  volumes:
    - ../..:/opt/hadoop
  env_file:
    - docker-config

x-replication:
  &replication
  OZONE-SITE.XML_ozone.server.default.replication: ${OZONE_REPLICATION_FACTOR:-1}

services:
  datanode:
    <<: *common-config
    ports:
      - 19864
      - 9882
    environment:
      <<: *replication
      OZONE_OPTS:
    command: ["ozone","datanode"]
  om:
    <<: *common-config
    environment:
      ENSURE_OM_INITIALIZED: /data/metadata/om/current/VERSION
      OZONE_OPTS:
      <<: *replication
    ports:
      - 9874:9874
      - 9862:9862
    command: ["ozone","om"]
  scm:
    <<: *common-config
    ports:
      - 9876:9876
      - 9860:9860
    environment:
      ENSURE_SCM_INITIALIZED: /data/metadata/scm/current/VERSION
      OZONE-SITE.XML_hdds.scm.safemode.min.datanode: ${OZONE_SAFEMODE_MIN_DATANODES:-1}
      OZONE_OPTS:
      <<: *replication
    command: ["ozone","scm"]
  httpfs:
    <<: *common-config
    environment:
      OZONE-SITE.XML_hdds.scm.safemode.min.datanode: ${OZONE_SAFEMODE_MIN_DATANODES:-1}
      <<: *replication
    ports:
      - 14000:14000
    command: [ "ozone","httpfs" ]
  s3g:
    <<: *common-config
    environment:
      OZONE_OPTS:
      <<: *replication
    ports:
      - 9878:9878
    command: ["ozone","s3g"]
  recon:
    <<: *common-config
    ports:
      - 9888:9888
    environment:
      OZONE_OPTS:
      <<: *replication
    command: ["ozone","recon"]
  iceberg-rest:
    image: tabulario/iceberg-rest:0.5.0
    ports:
      - 8181:8181
    environment:
      - AWS_ACCESS_KEY_ID=any
      - AWS_SECRET_ACCESS_KEY=any
      - AWS_REGION=us-east-1
      - CATALOG_WAREHOUSE=s3://warehouse/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://s3g:9878/
      - CATALOG_S3_PATH__STYLE__ACCESS=true

  spark-master:
    build: ./spark
    #image: bitnami/spark:3.5.0
    #command: >
    #  /bin/sh
    #/opt/bitnami/spark/bin/spark-sql --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,org.apache.ozone:ozone-filesystem-hadoop3:1.4.0,org.apache.iceberg:iceberg-hive-runtime:1.5.0,org.apache.iceberg:iceberg-hive-metastore:1.5.0,org.apache.iceberg:iceberg-aws-bundle:1.5.0
    #stdin_open: true
    #tty: true
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
    #  - ./ivy2:/opt/bitnami/spark/.ivy2/
      - ./spark.conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    #  - ./spark-event-logs:/opt/bitnami/spark/event-logs
    #  - ./extra-jars:/opt/bitnami/spark/extra-jars
    environment:
      - AWS_ACCESS_KEY_ID=any
      - AWS_SECRET_ACCESS_KEY=any
      - AWS_REGION=us-east-1
      - SPARK_MODE=master
    healthcheck:
      test: bin/spark-shell || exit 1
      interval: 30s
      retries: 10
      start_period: 10s
      timeout: 60s  
  spark-thriftserver:
    build: ./spark
    container_name: spark-thriftserver
    depends_on:
      spark-master:
        condition: service_healthy
    command:
      - sbin/start-thriftserver.sh
      - --master
      - spark://spark-master:7077
    environment:
      - AWS_ACCESS_KEY_ID=any
      - AWS_SECRET_ACCESS_KEY=any
      - AWS_REGION=us-east-1
    ports:
      -  10000:10000
      -  4040:4040
    volumes_from:
      - spark-master
    healthcheck:
      test: beeline help || exit 1
      interval: 10s
      retries: 10
      start_period: 5s
      timeout: 60s

  spark-worker:
      build: ./spark
      container_name: spark-worker
      depends_on:
        spark-master:
          condition: service_healthy
      environment:
        - SPARK_MODE=worker
        - SPARK_MASTER_URL=spark://spark-master:7077
        - SPARK_WORKER_MEMORY=2G
        - SPARK_WORKER_CORES=2
        - AWS_ACCESS_KEY_ID=any
        - AWS_SECRET_ACCESS_KEY=any
        - AWS_REGION=us-east-1
      volumes_from:
        - spark-master
    